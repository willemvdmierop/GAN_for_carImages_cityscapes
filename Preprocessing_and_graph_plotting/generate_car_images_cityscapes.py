# -*- coding: utf-8 -*-
"""Generate_Car_images_cityscapes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N1hPEJq1FKQiGsSmEAuMbvxXNcNLOnUi
"""

import sys
sys.path.append('/content/drive/My Drive/DL Classification (705)/v_03_with_carimages')

import os, sys, re
import cv2
from itertools import chain
import numpy as np
import torch
from torch.utils import data
import torchvision
from PIL import Image as PILImage
from skimage.measure import label, regionprops
import matplotlib.pyplot as plt
import json
import xml
from xml.dom import minidom
import util
import list_of_cityscapes_labels as lab
import os
from torchvision.utils import save_image
from torchvision import transforms

def transform_img(self, image, image_max):
    h_max, w_max = image_max[0], image_max[1]
    img_size = tuple((h_max, w_max))
    transform = transforms.Compose([transforms.ToPILImage(),
                                    transforms.Resize(img_size),
                                    transforms.ToTensor(),
                                    transforms.Normalize(mean=[0.407, 0.457, 0.485], std=[1, 1, 1])])
    image = transform(image)
    return image


def load_img(self, index):
    image = np.array(PILImage.open(os.path.join(self.image_dir, self.images[index])))
    image = self.transform_img(image, self.image_max)
    return image


def extract_segmentation_mask_cityscapes(fname, predicted_classes):
    mask = np.array(PILImage.open(fname))
    # get rid of classes we don't need, convert them to background
    for label in np.unique(mask):
        _l = lab.id2label[label]
        if not _l in predicted_classes:
            mask[mask == label] = 0

            # relabel the classes so that they are consecutive,
    # e.g. 0 for bgr, 1 for car, 2 for pedestrian, etc
    cityscapes_to_new = {}
    new_to_cityscapes = {}
    for idz, c in enumerate(predicted_classes[1:]):
        assert c in lab.label2id.keys()
        cityscapes_to_new[lab.label2id[c]] = idz + 1
        new_to_cityscapes[idz + 1] = lab.label2id[c]

    _cl = np.unique(mask)
    for c in _cl[1:]:
        mask[mask == c] = cityscapes_to_new[c]

    mask = torch.tensor(mask, dtype=torch.uint8)
    return mask


def extract_instance_mask_cityscapes(fname, predicted_classes):
    mask = torch.tensor(np.array(PILImage.open(fname)), dtype=torch.uint8)
    fname_segment = re.sub('instanceIds', 'labelIds', fname)
    mask_segmentation = extract_segmentation_mask_cityscapes(fname_segment, predicted_classes)
    mask_instances_bgr = mask * mask_segmentation
    instances = np.unique(mask_instances_bgr)
    list_of_masks = []
    for m in instances[1:]:
        _mask = torch.zeros(mask.shape, dtype=torch.uint8)
        _mask[mask_instances_bgr == m] = 1
        # plt.imshow(_mask)
        list_of_masks.append(_mask)

    return list_of_masks


def get_target(fname, dir_gt, predicted_classes):
    #print("fname: " + fname)
    file_name = fname
    gt_name = re.sub('leftImg8bit.png', 'gtFine_polygons.json', file_name)
    segm_name = re.sub("leftImg8bit", "gtFine_labelIds", file_name)
    instance_name = re.sub("leftImg8bit", 'gtFine_instanceIds', file_name)

    with open(gt_name) as f:
        cs = json.load(f)
    objects = cs['objects']
    boxes = []
    classes = []

    for obj in objects:
        classlabel = obj['label']
        if classlabel in predicted_classes:
            classes.append([lab.label2id[obj['label']]])
            x, y = zip(*obj['polygon'])
            min_x, max_x = min(x), max(x)
            min_y, max_y = min(y), max(y)
            bbox = [min_x, min_y, max_x, max_y]
            boxes.append(bbox)
    target = {}
    classes = torch.tensor(classes, dtype=torch.int64)
    boxes = torch.as_tensor(boxes, dtype=torch.float)
    target['boxes'] = boxes
    target['classes'] = classes
    masks = extract_instance_mask_cityscapes(instance_name, predicted_classes)
    target['masks'] = masks
    return target

directory = "/content/drive/My Drive/DL Classification (705)/leftImg8bit_trainvaltest/leftImg8bit/val/munster"
dir_cars = "/content/drive/My Drive/DL Classification (705)/v_03_with_carimages"
gt_dir = "/content/drive/My Drive/DL Classification (705)/gtFine_trainvaltest/gtFine/val/munster"
SAVED_MODELS_DIR = 'saved_models'
predicted_classes = ['car']
predicted_classes.insert(0, '__bgr__')

device = torch.device('cpu')
if torch.cuda.is_available():
   device = torch.device('cuda')

maskrcnn_args = {'num_classes': 91}
maskrcnn_model = model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True, **maskrcnn_args)
maskrcnn_model.eval()
threshold = 0.90
total = 0
for filename in sorted(os.listdir(directory)):
    if filename == '.DS_Store':
        continue
    cars_name = re.sub('leftImg8bit.png', 'carImage.png', filename)
    car_dir = os.path.join(dir_cars, cars_name)
    areas = []
    targets = get_target(os.path.join(gt_dir, filename), dir_gt=gt_dir, predicted_classes=predicted_classes)
    #print(len(targets['masks']))
    if len(targets['masks']) == 0:
        continue
    j = 0
    for i in range(len(targets['masks'])):
        max_mask = targets['masks'][i]
        max_mask = np.array(max_mask)
        # open image
        img = np.array(PILImage.open(os.path.join(directory, filename)))
        #plt.imshow(img)
        # this is for just black if we want color next lines
        # for i in range(3):
        #    img[:,:,i] *= max_mask
        # (51,255,51) RGB values of green
        img[:, :, 0][np.where(max_mask == 0)] = 255
        img[:, :, 1][np.where(max_mask == 0)] = 255
        img[:, :, 2][np.where(max_mask == 0)] = 255
        #plt.imshow(img)
        trans = transforms.ToTensor()
        img = trans(img)
        img = img.to(device)
        maskrcnn_model = maskrcnn_model.to(device)
        output = maskrcnn_model([img])
        # print('NN\'s Output', output)
        scores = output[0]['scores'].cpu()
        bboxes = output[0]['boxes'].cpu()
        classes = output[0]['labels'].cpu()
        mask = output[0]['masks'].cpu()
        best_idx = np.where(scores > threshold)
        # we keep the best predictions
        best_scores = scores[best_idx]
        best_classes = classes[best_idx]
        best_bboxes = bboxes[best_idx]
        if len(best_scores)  == 1 and best_classes[0] == 3:
            best_bboxes = bboxes[best_idx]
            if len(best_bboxes[0]) < 4:
                continue
            best_bboxes = np.array(best_bboxes.detach().squeeze())
            x1, y1, x2, y2 = best_bboxes[0],best_bboxes[1],best_bboxes[2],best_bboxes[3]
            transPIL = transforms.ToPILImage(mode='RGB')
            img = img.cpu()
            img = transPIL(img)
            img = img.crop((x1, y1, x2, y2))
            img = trans(img)
            cars_name_mask = re.sub('_000019', f'_{j}_000019', cars_name)
            if not os.path.exists(dir_cars + "/cars5"):
                os.mkdir(dir_cars + "/cars5")
            if not os.path.exists(dir_cars + "/cars5/" + cars_name_mask):
                #print("saving:  " + dir_cars + "/cars/" + cars_name)
                #plt.imsave(dir_cars + "/cars/" + cars_name, img)
                save_image(img, dir_cars + "/cars5/" + cars_name_mask)
            else:
                print("image already exists, overwriting image")
                save_image(img, dir_cars + "/cars5/" + cars_name_mask)
            j += 1
    total += j
    print(f"Saved {j} images, and a total of {total} images")
print(30 * "#" + "finished saving the cars" + 30 * "#")

